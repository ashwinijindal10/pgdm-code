{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# listing movies from bollyshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4 ,pandas as pd\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "url ='https://freemoviewap2019.com/hollywood_dub_movie{0}.php'\n",
    "\n",
    "movieCollections = pd.DataFrame({\n",
    "        'Title' : [] ,\n",
    "        'Url' : []\n",
    "    });\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "retries = Retry(total=5,\n",
    "                backoff_factor=0.1,\n",
    "                status_forcelist=[ 500, 502, 503, 504 ])\n",
    "\n",
    "session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "\n",
    "def SearchAllPages():\n",
    "    global movieCollections\n",
    "    global url  \n",
    "    status =200\n",
    "    pageNo =1    \n",
    "    while(pageNo<=100): #status !=404 and\n",
    "        new_url=url.format( 's_'+ str(pageNo) if pageNo>1 else '')\n",
    "        req= session.get(new_url)       \n",
    "        status= req.status_code     \n",
    "        print('{0} with status {1}'.format(new_url,status) )\n",
    "        if(status ==200):\n",
    "            rs = readPage(req.text)\n",
    "            movieCollections =  movieCollections.append( pd.DataFrame(rs))\n",
    "        pageNo+=1\n",
    "        \n",
    "            \n",
    " \n",
    "\n",
    "def readPage(text):\n",
    "        data= bs4.BeautifulSoup(text,'html5lib')\n",
    "        listitems= data.select('.w3_agile_featured_movies > .w3l-movie-gride-agile ')\n",
    "        titles =[item.select_one('.w3l-movie-text a').get_text() for item in listitems]\n",
    "        urls = [item.select_one('.w3l-movie-text a').get('href') for item in listitems]\n",
    "        return { 'Title' : titles , 'Url' : urls };\n",
    "    \n",
    "        \n",
    "        \n",
    "SearchAllPages()\n",
    "\n",
    "movieCollections.to_csv('bollyshare_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[######################                                                  ]  31%\r"
     ]
    }
   ],
   "source": [
    "import requests, bs4 ,re,urllib, pandas as pd\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import progressbar\n",
    "from time import sleep\n",
    "\n",
    "data = pd.read_csv(\"bollyshare_movies_final.csv\") \n",
    "imdb_path='https://www.imdb.com/search/title/?title={0}&adult=include&view=simple&count=1&year={1}'\n",
    "\n",
    "\n",
    "def getProgressBar(max):\n",
    "    return  progressbar.ProgressBar(maxval=max,widgets=[progressbar.Bar('#', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    \n",
    "    \n",
    "\n",
    "def getSession(retry=5):\n",
    "    session = requests.Session()\n",
    "    retries = Retry(total=retry,\n",
    "                backoff_factor=0.1,\n",
    "                status_forcelist=[ 500, 502, 503, 504 ])\n",
    "    session.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    session.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "    return session\n",
    "\n",
    "\n",
    "def getImdbRank(info):\n",
    "    try:\n",
    "        global imdb_path\n",
    "        session=getSession() \n",
    "        title = urllib.parse.quote_plus(info.get('title')) \n",
    "        url =imdb_path.format(title ,info.get('year'))\n",
    "        data=session.get(url)\n",
    "        data= bs4.BeautifulSoup(data.text,'html5lib')\n",
    "        itemDataText= data.select_one('div.lister-item .lister-item-content')  \n",
    "        if(itemDataText is not None):\n",
    "            return {\n",
    "            'title':itemDataText.select_one('.col-title span.lister-item-header span[title] a').get_text().strip(),\n",
    "            'rating': itemDataText.select_one('.col-imdb-rating').get_text().strip(),\n",
    "            'link':url\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print('getImdbRank ',e ,type(e).__name__)   \n",
    "    return {}\n",
    "\n",
    "\n",
    "def FillMetaData():\n",
    "        metaCollections = pd.DataFrame();\n",
    "        bar=getProgressBar(len(data.index))\n",
    "        bar.start()\n",
    "        session=getSession() \n",
    "        progress=1\n",
    "        for _,d in data.iterrows():\n",
    "            try:\n",
    "                req =session.get(d.Url)\n",
    "                status= req.status_code  \n",
    "                if(status ==200):\n",
    "                    rs= readPage(req.text)\n",
    "                    rs.update({'Url':d.Url})\n",
    "                    metaCollections=metaCollections.append(pd.DataFrame.from_dict([rs]))\n",
    "            except Exception as e:\n",
    "                print('FillMetaData',e,type(e).__name__)       \n",
    "            finally :\n",
    "                bar.update(progress)\n",
    "                progress+=1\n",
    "                \n",
    "        bar.finish()\n",
    "        return metaCollections\n",
    "           \n",
    "           \n",
    "        \n",
    "def readPage(text):\n",
    "    data= bs4.BeautifulSoup(text,'html5lib')\n",
    "    itemDataText= data.select('.list-group  a.list-group-item ')\n",
    "    itemData ={ itemText.text.split()[-1]:itemText.select_one('span.badge').get_text()  for itemText in itemDataText if itemText is not None }\n",
    "    \n",
    "    download_links={ 'Download Full Movie':data.find(lambda tag:tag.name==\"a\" and \"Download Full Movie\" in tag.text),\n",
    "                     'Download Full HD':data.find(lambda tag:tag.name==\"a\" and \"Download Full HD\" in tag.text)  }\n",
    "    \n",
    "    itemData.update({key : value.get('href') for key, value in download_links.items() if value is not None })\n",
    "    itemData.update({'Year' : re.sub('^.*\\((.*?)\\)[^\\(]*$', '\\g<1>', itemData.get(\"Movie\")) ,\n",
    "                     'Movie': re.sub(r'\\(.*?\\)', '', itemData.get(\"Movie\")) })\n",
    "    \n",
    "    rank=getImdbRank({ 'title': itemData['Movie'], 'year':itemData['Year']})\n",
    "    itemData.update({ 'IMDB_link': rank.get('link'),  'IMDB_rating' : rank.get('rating') })\n",
    "   # print(itemData)\n",
    "    return itemData\n",
    "\n",
    "metaCollections=FillMetaData()\n",
    "data=pd.merge(data, metaCollections, on='Url', how ='left')\n",
    "\n",
    "data.to_csv('bollyshare_movies_info.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
