{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "import random ,string\n",
    "\n",
    "img= cv2.imread('img/5.jpg')\n",
    "#print(img.shape)\n",
    "\n",
    "def show_image(val):\n",
    "    for i,s in enumerate(val):\n",
    "        cv2.imshow('Hello World'+ str(i),s)    \n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 300)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gray color\n",
    "\n",
    "gr=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "show_image([gr])\n",
    "\n",
    "\n",
    "gr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 300\n"
     ]
    }
   ],
   "source": [
    "h, w = img.shape[:2]\n",
    "\n",
    "print(h,w)\n",
    "\n",
    "trns= np.float32([[1,0,w/4],[0,1,h/4]])\n",
    "\n",
    "rt= cv2.getRotationMatrix2D((w/2,h/2),22,1)\n",
    "\n",
    "#img_t= cv2.transpose(img)\n",
    "\n",
    "img_t=cv2.warpAffine(img,rt,(w,h))\n",
    "\n",
    "show_image(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing INTER_LANCZOS4, cubic is best one\n",
    "#https://stackoverflow.com/questions/3112364/how-do-i-choose-an-image-interpolation-method-emgu-opencv\n",
    "img= cv2.imread('img/1.jpg')\n",
    "i1=cv2.resize(img,(700,700), interpolation = cv2.INTER_LINEAR  )\n",
    "i2=cv2.resize(img,(500,500), interpolation = cv2.INTER_LANCZOS4 )\n",
    "i3=cv2.pyrDown(cv2.pyrDown(cv2.pyrDown(img)))\n",
    "show_image([i1,i2,i3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping\n",
    "img1=cv2.rectangle(img, (55,55),(500,500),255)\n",
    "\n",
    "cropped= img[200:843, 222:1000]\n",
    "\n",
    "show_image([cropped,img1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blurring\n",
    "img= cv2.imread('img/5.jpg')\n",
    "img=cv2.resize(img,(500,500), interpolation = cv2.INTER_LANCZOS4 )\n",
    "\n",
    "#manual\n",
    "kernal= np.ones((3,3),np.float32)*1/2\n",
    "blur= cv2.filter2D(img, -1,kernal)\n",
    "\n",
    "#auto\n",
    "\n",
    "b1= cv2.blur(img,(2,2))\n",
    "b2= cv2.GaussianBlur(img,(3,3),0)\n",
    "b3= cv2.bilateralFilter(img,9,75,75)\n",
    "b4= cv2.fastNlMeansDenoisingColored(img,None,6,6,7,21)\n",
    "show_image([img,b3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image sharpening\n",
    "\n",
    "kernal = np.array([\n",
    "    [-1,-1,-1],\n",
    "    [-1,9,-1],\n",
    "    [-1,-1,-1]\n",
    "])\n",
    "\n",
    "sh= cv2.filter2D(img, -1, kernal)\n",
    "\n",
    "show_image([img, sh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threashholding  **\n",
    "\n",
    "img= cv2.imread('img/1.jpg')\n",
    "img=cv2.resize(img,(800,800), interpolation = cv2.INTER_LANCZOS4 )\n",
    "\n",
    "#img= cv2.bilateralFilter(img,9,75,75)\n",
    "img= cv2.GaussianBlur(img,(3,3),0)\n",
    "\n",
    "gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#ret,thrd= cv2.threshold(gray_img, 150, 255,cv2.THRESH_TOZERO)\n",
    "#thrd= cv2.adaptiveThreshold(gray_img, 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,3,5)\n",
    "ret,thrd= cv2.threshold(gray_img, 0, 255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "show_image([gray_img,thrd])\n",
    "#gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dialtion and erosion \n",
    "\n",
    "kernal = np.ones((5,5),np.uint8)\n",
    "\n",
    "#erosion\n",
    "er= cv2.erode(img,kernal,iterations =1)\n",
    "#dial\n",
    "di= cv2.dilate(img,kernal,iterations =1)\n",
    "\n",
    "#morpho\n",
    "\n",
    "opening = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernal)\n",
    "closing = cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernal)\n",
    "\n",
    "show_image([img,opening,closing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge detection\n",
    "img= cv2.imread('img/nk.jpg')\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img=cv2.resize(img,(400,500), interpolation = cv2.INTER_LANCZOS4 )\n",
    "\n",
    "\n",
    "img1= cv2.Canny(img, 100,200)\n",
    "\n",
    "show_image([img,img1])\n",
    "\n",
    "#cv2.getPerspectiveTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188.5, 131.5, 129.5, 121.5, 121.0, 91.0, 87.5, 85.0, 70.0, 67.5]\n",
      "18\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# finding contours\n",
    "img= cv2.imread('img/4.jpg')\n",
    "img=cv2.resize(img,(500,400), interpolation = cv2.INTER_LANCZOS4 )\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#blur\n",
    "gray= cv2.GaussianBlur(gray,(3,3),0)\n",
    "#ret,gray= cv2.threshold(gray, 50, 255,cv2.THRESH_TOZERO)\n",
    "\n",
    "#show_image([gray,img])\n",
    "\n",
    "gray= cv2.Canny(gray, 100,200)\n",
    "cnts, hr = cv2.findContours(gray.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "def get_cont_areas(cntrs):\n",
    "    areas=[]\n",
    "    for c in cntrs:\n",
    "        areas.append(cv2.contourArea(c))\n",
    "    return areas\n",
    "\n",
    "\n",
    "#actual image cont draw\n",
    "img1=img.copy()\n",
    "cv2.drawContours(img1 , cnts,-1,(0,255,0),3)\n",
    "\n",
    "#blank image cotours draw\n",
    "blank_img= np.zeros((gray.shape[0],gray.shape[1],3))  \n",
    "blank_img1= blank_img.copy()\n",
    "cv2.drawContours(blank_img1 , cnts,-1,(0,255,0),3)\n",
    "\n",
    "\n",
    "#show max cot.\n",
    "max_cons = sorted(cnts,key=cv2.contourArea,reverse=True)[:]\n",
    "img2=img.copy()\n",
    "cv2.drawContours(img2 , max_cons,-1,(0,255,0),3)\n",
    "print(get_cont_areas(max_cons[:10]))\n",
    "\n",
    "show_image([blank_img1,img2])\n",
    "\n",
    "\n",
    "\n",
    "#finding top contours and convexhull \n",
    "def showContoursInSeries():\n",
    "    for cnt in max_cons[:2]:\n",
    "        hull= cv2.convexHull(cnt)\n",
    "        approx=cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt, True),True)\n",
    "        print(len(approx)) #no of polygons\n",
    "        img3=img.copy()\n",
    "        cv2.drawContours(img3 ,[hull],-1,(0,255,0),3)\n",
    "        show_image([img3])\n",
    "        \n",
    "showContoursInSeries()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blob detections\n",
    "import cv2\n",
    "\n",
    "#skin detection option possible but not good\n",
    "img= cv2.imread('img/Sunflowers.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "img=cv2.resize(img,(500,600), interpolation = cv2.INTER_LANCZOS4 )\n",
    "\n",
    "\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 10\n",
    "params.maxThreshold = 20000\n",
    "params.filterByArea = True\n",
    "detector=cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "\n",
    "\n",
    "keypoints=detector.detect(img)\n",
    "\n",
    "#draw detect blobs\n",
    "blank = np.zeros((2,2))\n",
    "blobs=cv2.drawKeypoints(img,keypoints,blank,(0,0,255),cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "\n",
    "show_image([img,blobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image features detection ##pogo cam\n",
    "#use best preformer sift and surf\n",
    "#https://github.com/anaustinbeing/haar-cascade-files\n",
    "import cv2\n",
    "\n",
    "img= cv2.imread('img/1.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "img=cv2.resize(img,(600,600), interpolation = cv2.INTER_LANCZOS4 )\n",
    "\n",
    "orb= cv2.ORB_create(500,1.5)\n",
    "keypoints,desc=orb.detectAndCompute(img, None)\n",
    "\n",
    "img1= cv2.drawKeypoints(img,keypoints,outImage=None,color=(255,0,255))\n",
    "\n",
    "show_image([img1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no face..\n",
      "no face..\n",
      "no face..\n"
     ]
    }
   ],
   "source": [
    "#face recognization \n",
    "#install dlib -https://medium.com/analytics-vidhya/how-to-install-dlib-library-for-python-in-windows-10-57348ba1117f#:~:text=Now%20we%20can%20install%20dlib,need%20to%20install%20CMake%20library.&text=Then%2C%20you%20can%20install%20dlib%20library%20using%20pip%20install%20.&text=After%20passing%20enter%2C%20you%20laptop,run%20the%20C%2C%20C%2B%2B%20Compiler.\n",
    "#Localize the tips of your fingers\n",
    "#help doc https://www.pyimagesearch.com/2019/12/16/training-a-custom-dlib-shape-predictor/\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy \n",
    "from collections import OrderedDict\n",
    "from imutils import face_utils\n",
    "\n",
    "FACIAL_LANDMARKS_IDXS = OrderedDict([\n",
    "    (\"mouth\", (48, 68)),\n",
    "\t(\"right_eyebrow\", (17, 22)),\n",
    "\t(\"left_eyebrow\", (22, 27)),\n",
    "\t(\"right_eye\", (36, 42)),\n",
    "\t(\"left_eye\", (42, 48)),\n",
    "\t(\"nose\", (27, 35)),\n",
    "\t(\"jaw\", (0, 17))\n",
    "])\n",
    "\n",
    "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "\n",
    "#shapes = numpy.matrix([[p.x, p.y] for p in predictor(image, rect[0]).parts()])\n",
    "\n",
    "def annotate_landmarks(im, landmarks):\n",
    "    im = im.copy()\n",
    "    for idx, pos in enumerate(landmarks):\n",
    "        pos=tuple(pos)\n",
    "        cv2.putText(im, str(idx),pos ,\n",
    "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    \n",
    "                    color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
    "    return im\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()   \n",
    "    #image=cv2.resize(frame,(700,700), interpolation = cv2.INTER_LANCZOS4 )\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray,1)\n",
    "    \n",
    "    if(len(rects) == 0):\n",
    "        print(\"no face..\")\n",
    "        continue\n",
    "    \n",
    "    shape = predictor(gray, rects[0])\n",
    "    landmarks = face_utils.shape_to_np(shape)\n",
    "    #print(landmarks)\n",
    "    image_with_landmarks = annotate_landmarks(frame, landmarks)\n",
    "    #show face bounding box\n",
    "    (x, y, w, h) = face_utils.rect_to_bb(rects[0])\n",
    "    cv2.rectangle(image_with_landmarks, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Live', image_with_landmarks )\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "#output = face_utils.visualize_facial_landmarks(image, shapes)\n",
    "\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
